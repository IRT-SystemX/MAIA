{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0ce08423",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import shapely.geometry as sgeo\n",
    "import yaml\n",
    "import numpy as np\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "09e28383",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"snakemake\" in locals():\n",
    "    demand_path = snakemake.input[\"demand\"]\n",
    "    enrichment_path = snakemake.input[\"enrichment\"]\n",
    "    output_path = snakemake.output[0]\n",
    "    seed = int(snakemake.params[\"seed\"])\n",
    "\n",
    "else:\n",
    "    demand_path = \"../../results/paris/demand/filtered/demand_main_1000.gpkg\"\n",
    "    enrichment_path = \"../../resources/paris/enrichment.yml\"\n",
    "    output_path = \"../../results/paris/demand/enriched/demand_main_1000.gpkg\"\n",
    "    seed = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "dde6d9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialie RNG\n",
    "random_state = np.random.RandomState(seed)\n",
    "sample_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e16b29f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load demand\n",
    "df_demand = gpd.read_file(demand_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d518e70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load enrichment \n",
    "with open(enrichment_path) as f:\n",
    "    enrichment = yaml.load(f, yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d805382e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define distribution factories\n",
    "distribution_factories = {}\n",
    "\n",
    "def uniform_distribution_factory(definition):\n",
    "    return scipy.stats.uniform(\n",
    "        loc = definition[\"lower\"], \n",
    "        scale = definition[\"upper\"] - definition[\"lower\"]) \n",
    "\n",
    "distribution_factories[\"uniform\"] = uniform_distribution_factory\n",
    "\n",
    "def poisson_distribution_factory(definition):\n",
    "      return scipy.stats.poisson(mu = definition[\"mean\"])\n",
    "\n",
    "distribution_factories[\"poisson\"] = poisson_distribution_factory\n",
    "\n",
    "def normal_distribution_factory(definition):\n",
    "    return scipy.stats.norm(loc = definition[\"mean\"], scale = definition[\"std\"])\n",
    "\n",
    "distribution_factories[\"normal\"] = normal_distribution_factory\n",
    "\n",
    "def truncated_normal_factory(definition):\n",
    "    lower, upper = None, None\n",
    "\n",
    "    if \"lower\" in definition:\n",
    "        lower = (definition[\"lower\"] - definition[\"mean\"]) / definition[\"std\"]\n",
    "\n",
    "    if \"upper\" in definition:\n",
    "        upper = (definition[\"upper\"] - definition[\"mean\"]) / definition[\"std\"]\n",
    "\n",
    "    return scipy.stats.truncnorm(loc = definition[\"mean\"], scale = definition[\"std\"], \n",
    "        a = lower, b = upper)\n",
    "    \n",
    "distribution_factories[\"truncaed_normal\"] = truncated_normal_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d40ae824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check profiles\n",
    "profiles = df_demand[\"passenger_profile\"].unique()\n",
    "\n",
    "for profile in profiles: \n",
    "    assert profile in enrichment[\"profiles\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "402d77e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profile filters\n",
    "profile_filters = {}\n",
    "\n",
    "for profile in profiles:\n",
    "    profile_filters[profile] = df_demand[\"passenger_profile\"] == profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "696653ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sampling procedure\n",
    "def sample(count, definition):\n",
    "    if isinstance(definition, dict) and \"distribution\" in definition:\n",
    "        distribution = distribution_factories[definition[\"distribution\"]](definition)\n",
    "        values = []\n",
    "\n",
    "        while len(values) < count:\n",
    "            candidates = distribution.rvs(sample_size)\n",
    "\n",
    "            if \"minimum\" in definition:\n",
    "                candidates = [candidates >= definition[\"minimum\"]]\n",
    "\n",
    "            if \"maximum\" in definition:\n",
    "                candidates = [candidates <= definition[\"minimum\"]]\n",
    "\n",
    "            values += list(candidates)\n",
    "\n",
    "        return np.array(values)[:count]\n",
    "    else:\n",
    "        return definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6a1e99ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum wait time\n",
    "if not \"maximum_wait_time\" in df_demand.columns:\n",
    "    for profile in profiles:\n",
    "        definition, f = enrichment[\"profiles\"][profile][\"maximum_wait_time\"], profile_filters[profile]\n",
    "        df_demand.loc[f, \"maximum_wait_time\"] = sample(np.count_nonzero(f), definition)\n",
    "\n",
    "df_demand[\"maximum_wait_time\"] = df_demand[\"maximum_wait_time\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a6268508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interaction time\n",
    "if not \"interaction_time\" in df_demand.columns:\n",
    "    for profile in profiles:\n",
    "        definition, f = enrichment[\"profiles\"][profile][\"interaction_time\"], profile_filters[profile]\n",
    "        df_demand.loc[f, \"interaction_time\"] = sample(np.count_nonzero(f), definition)\n",
    "\n",
    "df_demand[\"interaction_time\"] = df_demand[\"interaction_time\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d92f1861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prebooking time\n",
    "if not \"prebooking_time\" in df_demand.columns:\n",
    "    for profile in profiles:\n",
    "        if \"prebooking_time\" in enrichment[\"profiles\"][profile]:\n",
    "            definition, f = enrichment[\"profiles\"][profile][\"prebooking_time\"], profile_filters[profile]\n",
    "            df_demand.loc[f, \"prebooking_time\"] = sample(np.count_nonzero(f), definition)\n",
    "\n",
    "        else:\n",
    "            df_demand.loc[f, \"prebooking_time\"] = 0.0\n",
    "\n",
    "df_demand[\"prebooking_time\"] = df_demand[\"prebooking_time\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a848d538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pooling\n",
    "if not \"is_poolable\" in df_demand.columns:\n",
    "    for profile in profiles:\n",
    "        f = profile_filters[profile]\n",
    "        df_demand.loc[f, \"is_poolable\"] = enrichment[\"profiles\"][profile][\"poolable\"]\n",
    "\n",
    "if not \"detour_factor\" in df_demand.columns:\n",
    "    for profile in profiles:\n",
    "            f = profile_filters[profile]\n",
    "            definition = enrichment[\"profiles\"][profile][\"detour_factor\"]\n",
    "            df_demand.loc[f, \"detour_factor\"] = sample(np.count_nonzero(f), definition)\n",
    "\n",
    "df_demand[\"is_poolable\"] = df_demand[\"is_poolable\"].astype(bool)\n",
    "df_demand[\"detour_factor\"] = df_demand[\"detour_factor\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5853c80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group size\n",
    "if not \"group_size\" in df_demand.columns:\n",
    "    for profile in profiles:\n",
    "        definition, f = enrichment[\"profiles\"][profile][\"group_size\"], profile_filters[profile]\n",
    "        df_demand.loc[f, \"group_size\"] = sample(np.count_nonzero(f), definition)\n",
    "\n",
    "df_demand[\"group_size\"] = df_demand[\"group_size\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47048976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add request ID\n",
    "df_demand[\"request_id\"] = np.arange(len(df_demand)).astype(str)\n",
    "df_demand[\"request_id\"] += \":\" + df_demand[\"passenger_profile\"]\n",
    "\n",
    "# Convert departure time\n",
    "df_demand[\"departure_time\"] = df_demand[\"reference_time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7bb1b0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output\n",
    "df_demand.to_file(output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
