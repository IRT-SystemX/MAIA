{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce08423",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import gzip, re, pickle\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e28383",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"snakemake\" in locals():\n",
    "    demand_path = snakemake.input[\"demand\"]\n",
    "    simulation_path = snakemake.input[\"simulation\"]\n",
    "    output_path = snakemake.output[0]\n",
    "\n",
    "else:\n",
    "    demand_path = \"../../results/paris/demand/profile/demand_main_economy_1000.gpkg\"\n",
    "    simulation_path = \"../../results/paris/matsim/output_main_economy_1000_100_14\"\n",
    "    output_path = \"../../results/paris/analysis/main_economy_1000_100_14.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8929e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare output\n",
    "output = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2715da2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load demand\n",
    "df_demand = gpd.read_file(demand_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8c1a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_regex = re.compile(rb\"time=\\\"(.+?)\\\"\")\n",
    "request_regex = re.compile(rb\"request=\\\"(.+?)\\\"\")\n",
    "person_regex = re.compile(rb\"person=\\\"(.+?)\\\"\")\n",
    "unshared_ride_time_regex = re.compile(rb\"unsharedRideTime=\\\"(.+?)\\\"\")\n",
    "\n",
    "df_events = df_demand[[\"request_id\"]].copy().set_index(\"request_id\")\n",
    "\n",
    "departure_times = {}\n",
    "unshared_ride_time = {}\n",
    "\n",
    "# Read events\n",
    "with gzip.open(\"{}/output_events.xml.gz\".format(simulation_path)) as f:\n",
    "    for line in f:\n",
    "        if b\"submitted\" in line:\n",
    "            time = float(time_regex.search(line).group(1))\n",
    "            request = \":\".join(person_regex.search(line).group(1).split(b\",\")[0].decode().split(\":\")[1:3])\n",
    "            df_events.loc[request, \"submission_time\"] = time\n",
    "            unshared_ride_time[request] = float(unshared_ride_time_regex.search(line).group(1))\n",
    "\n",
    "        if b\"passenger waiting\" in line:\n",
    "            time = float(time_regex.search(line).group(1))\n",
    "            request = \":\".join(person_regex.search(line).group(1).split(b\",\")[0].decode().split(\":\")[1:3])\n",
    "            df_events.loc[request, \"departure_time\"] = time \n",
    "            departure_times[request] = time\n",
    "\n",
    "        if b\"passenger picked up\" in line:\n",
    "            time = float(time_regex.search(line).group(1))\n",
    "            request = \":\".join(person_regex.search(line).group(1).split(b\",\")[0].decode().split(\":\")[1:3])\n",
    "            df_events.loc[request, \"pickup_time\"] = time \n",
    "            df_events.loc[request, \"wait_time\"] = time - departure_times[request]\n",
    "\n",
    "        if b\"passenger dropped off\" in line:\n",
    "            time = float(time_regex.search(line).group(1))\n",
    "            request = \":\".join(person_regex.search(line).group(1).split(b\",\")[0].decode().split(\":\")[1:3])\n",
    "            df_events.loc[request, \"dropoff_time\"] = time \n",
    "            df_events.loc[request, \"travel_time\"] = time - departure_times[request]\n",
    "            df_events.loc[request, \"detour_factor\"] = (time - departure_times[request]) / unshared_ride_time[request]\n",
    "\n",
    "        if b\"PassengerRequest rejected\" in line:\n",
    "            time = float(time_regex.search(line).group(1))\n",
    "            request = \":\".join(person_regex.search(line).group(1).split(b\",\")[0].decode().split(\":\")[1:3])\n",
    "            df_events.loc[request, \"rejection_time\"] = time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7d9749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge times\n",
    "df_demand = pd.merge(df_demand[[\n",
    "    \"request_id\", \"passenger_profile\",\n",
    "]], df_events, on = \"request_id\", how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f57745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate for general passenger profile\n",
    "df_demand = pd.concat([df_demand, df_demand.assign(passenger_profile = \"all\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aad590a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily = pd.DataFrame(index = pd.Index(df_demand[\"passenger_profile\"].unique(), name = \"passenger_profile\")).reset_index()\n",
    "\n",
    "df_daily = pd.merge(df_daily,\n",
    "    df_demand.groupby(\"passenger_profile\").size().reset_index(name = \"requests\"),\n",
    "    on = \"passenger_profile\", how = \"left\")\n",
    "\n",
    "df_daily = pd.merge(df_daily,\n",
    "    df_demand[~df_demand[\"rejection_time\"].isna()].groupby(\"passenger_profile\").size().reset_index(name = \"rejections\"),\n",
    "    on = \"passenger_profile\", how = \"left\")\n",
    "\n",
    "df_daily[\"rejection_rate\"] = df_daily[\"rejections\"] / df_daily[\"requests\"]\n",
    "\n",
    "df_mean = df_demand[[\"passenger_profile\", \"wait_time\", \"travel_time\", \"detour_factor\"]].copy()\n",
    "df_mean = df_mean.groupby(\"passenger_profile\")[[\"wait_time\", \"travel_time\", \"detour_factor\"]].mean().reset_index()\n",
    "df_daily = pd.merge(df_daily, df_mean, how = \"left\", on = \"passenger_profile\")\n",
    "\n",
    "output[\"daily\"] = df_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed8d72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hourly = pd.DataFrame(index = pd.MultiIndex.from_product([\n",
    "    np.arange(24), df_demand[\"passenger_profile\"].unique()], \n",
    "    names = [\"hour\", \"passenger_profile\"])).reset_index()\n",
    "\n",
    "for slot in [\"submission\", \"departure\", \"pickup\", \"dropoff\", \"rejection\"]:\n",
    "    df_partial = df_demand[[slot + \"_time\", \"passenger_profile\"]].copy()\n",
    "    df_partial[\"hour\"] = df_partial[slot + \"_time\"] // 3600\n",
    "    df_partial = df_partial.groupby([\"hour\", \"passenger_profile\"]).size().reset_index(name = slot + \"s\")\n",
    "    df_hourly = pd.merge(df_hourly, df_partial, how = \"left\")\n",
    "\n",
    "df_mean = df_demand[[\"departure_time\", \"passenger_profile\", \"wait_time\", \"travel_time\", \"detour_factor\"]].copy()\n",
    "df_mean[\"hour\"] = df_mean[\"departure_time\"] // 3600\n",
    "df_mean = df_mean.groupby([\"hour\", \"passenger_profile\"])[[\"wait_time\", \"travel_time\", \"detour_factor\"]].mean().reset_index()\n",
    "df_hourly = pd.merge(df_hourly, df_mean, how = \"left\", on = [\"hour\", \"passenger_profile\"])\n",
    "\n",
    "df_hourly[\"rejection_rate\"] = df_hourly[\"rejections\"] / df_hourly[\"submissions\"]\n",
    "\n",
    "df_hourly = df_hourly.fillna(0.0)\n",
    "\n",
    "output[\"hourly\"] = df_hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cda2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_path, \"wb+\") as f:\n",
    "    pickle.dump(output, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
