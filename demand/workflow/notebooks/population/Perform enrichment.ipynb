{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"snakemake\" in locals():\n",
    "    target_path = snakemake.input[\"target\"]\n",
    "    distribution_path = snakemake.input[\"distribution\"]\n",
    "    output_path = snakemake.output[0]\n",
    "    attributes = snakemake.params[\"attributes\"]\n",
    "    weight = snakemake.params[\"weight\"] if \"weight\" in snakemake.params.keys() else \"weight\"\n",
    "    match = snakemake.params[\"match\"] if \"match\" in snakemake.params.keys() else []\n",
    "    seed = snakemake.params[\"seed\"]\n",
    "    \n",
    "else:\n",
    "    target_path = \"../../../results/brussels/population/passengers_with_departure_hour_seed2000.parquet\"\n",
    "    distribution_path = \"../../../results/brussels/airport/daily_totals.parquet\"\n",
    "    output_path = \"../../../results/brussels/population/passengers_with_access_seed2000.parquet\"\n",
    "    attributes = [\"is_access\"]\n",
    "    \n",
    "    weight = \"weight\"\n",
    "    match = []\n",
    "    seed = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df_target = gpd.read_parquet(target_path)\n",
    "df_distribution = pd.read_parquet(distribution_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random\n",
    "random = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(match) == 0:\n",
    "    df_sample = df_distribution[attributes + [weight]].sample(\n",
    "        n = len(df_target), replace = True, weights = weight, random_state = random)\n",
    "    \n",
    "    for column in attributes:\n",
    "        df_target[column] = df_sample[column].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(match) > 0:\n",
    "    df_slots = df_distribution[match].drop_duplicates()\n",
    "\n",
    "    df_sample = pd.DataFrame({\n",
    "        column: [np.nan] * len(df_target) for column in attributes\n",
    "    })\n",
    "\n",
    "    for index, row in df_slots.iterrows():\n",
    "        f_target = np.ones((len(df_target),), dtype = bool)\n",
    "        f_distribution = np.ones((len(df_distribution),), dtype = bool)\n",
    "\n",
    "        for column in match:\n",
    "            f_target &= df_target[column] == row[column]\n",
    "            f_distribution &= df_distribution[column] == row[column]\n",
    "\n",
    "        df_sample = df_distribution.loc[f_distribution, attributes + [weight]].sample(\n",
    "            n = np.count_nonzero(f_target), replace = True, weights = weight, random_state = random)\n",
    "        \n",
    "        for column in attributes:\n",
    "            df_target.loc[f_target, column] = df_sample[column].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output\n",
    "df_target.to_parquet(output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
